#summary Performance tables.
#sidebar TOC

= Introduction =

This page presents some basic performance data for the programs supplied with ParaFEM.

= p121 =

The tables below give some performance figures for program p121 (3D small strain elasticity) using various systems. Basic data about the problem are listed as follows:

{{{
1,000,000 elements 
4,090,601 nodes
12,059,800 equations
}}}

== HECToR Phase 2b ==

|| Number of processors || Number of cores || Time (s) in solver || Speed up || Efficiency || Total time (s) || Speed up || Efficiency ||
||12{{{*}}}||12||-||-||-||-||-||-||
||2||24||1058||-||-||1124||-||-||
||4||48||478||-||-||535||-||-||
||8||96||247||-||-||299||-||-||
||16||192||129||-||-||184||-||-||
||32||384||67||-||-||118||-||-||
||64||768||36||-||-||87||-||-||
||128||1536||24||-||-||88||-||-||
||256{{{*}}}||3072||-||-||-||-||-||-||

{{{
* Memory fault reported by the system.
}}}

== CINECA IBM SP6 ==

|| Number of processors || Number of cores || Time (s) in solver || Speed up || Efficiency || Total time (s) || Speed up || Efficiency ||
||16||32{{{*}}}||-||-||-||-||-||-||
||32||64||250||-||-||382||-||-||
||64||128||124||-||-||253||-||-||
||128||256||66||-||-||193||-||-||
||256||512||38||-||-||168||-||-||

{{{
* Job failed with no error message
}}}

== Mare Nostrum IBM PowerPC 970MP ==

|| Number of processors || Number of cores || Time (s) in solver || Speed up || Efficiency || Total time (s) || Speed up || Efficiency ||
||{{{*}}}||8||2818||-||-||3036||-||-||
||8||16||2445||-||-||2644||-||-||
||16||32||1234||-||-||1417||-||-||
||32||64||638||-||-||813||-||-||
||64||128||326||-||-||500||-||-||
||128||256||209||-||-||378||-||-||
||256||512||187||-||-||386||-||-||

{{{
* This job used 1 core on 8 compute nodes. This was so that the program could reserve sufficient memory to run. The notional cost of the job was 32 cores, even though only 8 cores were used for execution.
}}}

= p126 =

== HECToR Phase 2b ==

The table below gives some performance figures for program p126 (direct numerical solution of the Navier Stokes equations) using HECToR Phase 2b. Basic data about the problem are listed as follows:

{{{
1,000,000 elements 
4,090,601 nodes
12,792,398 equations
}}}

|| Number of processors || Number of cores || Time (s) in solver || Speed up || Efficiency || Total time (s) || Speed up || Efficiency ||
||8||96||12932||-||-||13011||-||-||
||16||192||6040||-||-||6109||-||-||
||32||384||3119||-||-||3200||-||-||
||64||768||1987||-||-||2052||-||-||
||128||1536||1259||-||-||1321||-||-||
||256{{{*}}}||3072||-||-||-||-||-||-||

{{{
* Memory fault reported by the system.
}}}

= prog83 =

== HECToR Phase 2a ==

The tables below give performance figures for program prog83 using HECToR Phase 2a, for different sizes of problem. Program prog83 solves a 3D elasticity problem using the boundary element method. Basic data regarding problem size are listed before each table.

{{{
600 elements
602 nodes 
1800 equations
}}}

|| Number of processors || Number of cores || Time (s) in solver || Speed up || Efficiency || Total time (s) || Speed up || Efficiency ||
||1||1||2.4||-||-||5.7||-||-||
||1||2||1.2||-||-||2.8||-||-||
||1||4||0.7||-||-||1.9||-||-||
||2||8||0.4||-||-||1.9||-||-||
||4||16||0.2||-||-||1.5||-||-||
||8||32||0.1||-||-||1.3||-||-||

{{{
9600 elements
9602 nodes 
28800 equations
}}}

|| Number of processors || Number of cores || Time (s) in solver || Speed up || Efficiency || Total time (s) || Speed up || Efficiency ||
||16||16||287||-||-||343||-||-||
||16||32||204||-||-||238||-||-||
||16||64||171||-||-||194||-||-||
||32||128||102||-||-||118||-||-||
||64||256||57||-||-||70||-||-||
||128||512||34||-||-||46||-||-||
||256||1024||24||-||-||36||-||-||

== CINECA IBM SP6 ==

The tables below give performance figures for program prog83 using CINECA's IBM SP6, for different sizes of problem. Program prog83 solves a 3D elasticity problem using the boundary element method. Basic data regarding problem size are listed before each table.

{{{
600 elements
602 nodes 
1800 equations
}}}

|| Number of processors || Number of cores || Time (s) in solver || Speed up || Efficiency || Total time (s) || Speed up || Efficiency ||
||1||2||0.6||-||-||2.1||-||-||
||2||4||0.3||-||-||1.4||-||-||
||4||8||0.3||-||-||1.1||-||-||
||8||16||0.15||-||-||0.7||-||-||
||16||32||0.14||-||-||0.67||-||-||

{{{
9600 elements
9602 nodes 
28800 equations
}}}

|| Number of processors || Number of cores || Time (s) in solver || Speed up || Efficiency || Total time (s) || Speed up || Efficiency ||
||8{{{*}}}||16||-||-||-||-||-||-||
||16||32||63||-||-||112||-||-||
||32||64||33||-||-||62||-||-||
||64||128||17||-||-||37||-||-||
||128||256||9||-||-||24||-||-||
||256||512||5||-||-||18||-||-||
||512||1024||4||-||-||15||-||-||

{{{
* Job failed with no error message
}}}

Note: Initial runs for this problem size did not complete and there were no error messages. The fix was to add the following command to the loadleveller batch script:

{{{
#@ resources = ConsumableMemory(3400MB)
}}}

This specifies the memory required per core, thus ensuring dedicated access to the memory on the node(s) used.